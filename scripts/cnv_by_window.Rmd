---
title: "CNV calling over windows"
author: "Simon Renny-Byfield"
date: "July 1, 2015"
output: html_document
---

The purpose of the document is to detail the analysis of CNV over windows across the genome. In this case the approach is similar to that detailed in `custom_cnv_v2.Rmd` in that it uses a z-score (e.g. standard deviations away from the mean) and the difference in read-depth between the sample and a reference genome (in this case B73). As such, it borrows heavily from the code employed in `custom_cnv_v2.Rmd`, with some slight modificartions.

##Generating the coverage data

The coverage information is calcualted using `.bam` files generated by Vince Buffalo and the following script.

```
#!/bin/bash -l
#!/bin/bash
#SBATCH -D /group/jrigrp4/CNVsim/data/windows
#SBATCH -o /group/jrigrp4/custom_cnv/logs/mcov_out_log-%j.txt
#SBATCH -e /group/jrigrp4/custom_cnv/logs/mcov_err_log-%j.txt
#SBATCH -J SimMulticov
#SBATCH --array=0-4
#SBATCH --mem-per-cpu=12000
#SBATCH --cpus-per-task=1

##Simon Renny-Byfield, UC Davis, June 2015

# define the windows of interest
windows=(50 250 500 1000 2000)

echo "Job Starting: "
date
echo "Working on window size ${windows[$SLURM_ARRAY_TASK_ID]}"

cmd="bedtools multicov -bams /group/jrigrp4/CNVsim/data/windows/*sorted.bam -bed <(bedtools makewindows -g ../../../custom_cnv/data/chrLenFilev2.txt -w ${windows[$SLURM_ARRAY_TASK_ID]}) -q 30 > window_${windows[$SLURM_ARRAY_TASK_ID]}bp_coverage.txt"
echo $cmd
eval $cmd

echo "Jobe Done: "
date
``` 

Next, the data have to be GC normalized using a script that looks like this:

```
#!/bin/bash -l
#SBATCH -D /group/jrigrp4/custom_cnv/data
#SBATCH -o /group/jrigrp4/custom_cnv/logs/gc_out_log-%j.txt
#SBATCH -e /group/jrigrp4/custom_cnv/logs/gc_err_log-%j.txt
#SBATCH -J gc
#SBATCH --array=0-2
#SBATCH --mem-per-cpu=20000
#SBATCH --cpus-per-task=1

##Simon Renny-Byfield, UC Davis, April 2015
 

windows=(500 1000 2000)

echo "Starting Job:"
date

cmd="Rscript ../scripts/gcNorm_sim.R window_${windows[$SLURM_ARRAY_TASK_ID]}bp_coverage.txt window_${windows[$SLURM_ARRAY_TASK_ID]}bp_GC.txt gc_normalized_${windows[$SLURM_ARRAY_TASK_ID]}bp.RData"
echo $cmd
eval $cmd

echo "Job done: "
date
```

This scripts calls an `R` script which utilizes the `EDASeq` package and looks like this:

```{r,eval=FALSE}
###
# Normalize read-depth over sliding windows across the Maize genome
###

# Simon Renny-Byfield, June '15, UC Davis

options(echo=TRUE) # if you want see commands in output file
args <- commandArgs(trailingOnly = TRUE)
print(args)

# load some useful libraries
library(data.table)
library(ggplot2)
library(reshape2)
library(EDASeq)

# load in the data
chr6cov<-read.table(args[1])

norm.df<-subset(chr6cov, select=-c(1:3))
# normalize by column total
norm.df<-sweep(norm.df, 2, colSums(subset(norm.df)), FUN="/")
norm.df<-sweep(norm.df, 2, 1e6, FUN="*")

#load in teh gc data
ch6_gc<-read.table(args[2])
#attach it to norm.df

gc<-ch6_gc$V5
norm.df<-data.matrix(norm.df)
# now try to normalize the data according to GC content
chr6Coverage<-withinLaneNormalization(x=norm.df, y=gc, which="loess", round=FALSE)
# modify make a new data.table of the gc normalized counts
chr6Coverage<-data.table(chr6Coverage)
chr6Coverage<-cbind(chr6cov[,1:3],chr6Coverage,gc)

save(chr6Coverage,file=args[3])
```

##Generating the Tajima's D over the same windows

Next we need to generate the Tajima's D data. This is done using `ANGSD` as follows:

```
#!/bin/bash -l
#!/bin/bash
#SBATCH -D /group/jrigrp4/custom_cnv/sfs/windows
#SBATCH -o /group/jrigrp4/custom_cnv/logs/sfs_out_log-%j.txt
#SBATCH -e /group/jrigrp4/custom_cnv/logs/sfs_err_log-%j.txt
#SBATCH -J SFS&TD
#SBATCH --mem-per-cpu=10000
#SBATCH --cpus-per-task=18

##Simon Renny-Byfield, UC Davis, June 2015

echo "Starting Job:"
date

# calculate the .saf file
cmd="angsd -bam ../../../teosinte_parents/file.list.txt -doSaf 2 -out teosinte19 -anc ../../../teosinte_parents/genomes/TRIP.fa -ref ../../../teosinte_parents/genomes/Zea_mays.AGPv3.22.dna.genome.fa -GL 1 -P 18 -indF ../../../teosinte_parents/angsd_outpu$
echo $cmd
#eval $cmd

# formally calculate the SFS
cmd="realSFS teosinte19.saf 38 -maxIter 100 -P 12 > teosinte19.sfs"
echo $cmd
#eval $cmd

# no fiure out region wide thetas
cmd="angsd -bam ../../../teosinte_parents/file.list.txt -out teosinte19_thetas.sfs -doThetas 1 -doSaf 2 -ref ../../../teosinte_parents/genomes/Zea_mays.AGPv3.22.dna.genome.fa -indF ../../../teosinte_parents/angsd_output/teo_parents19e-6.indF -pest teosin$
echo $cmd
#eval $cmd

# make the .bed file
cmd="thetaStat make_bed teosinte19_thetas.sfs.thetas.gz"
echo $cmd
eval $cmd

#calculate Tajimas D
cmd="thetaStat do_stat teosinte19_thetas.sfs.thetas.gz -nChr 19 -win 1000 -step 1000 -outnames teosinte19.teothetasWindow.gz"
echo $cmd
eval $cmd

#now clean up the output..
cmd="cat teosinte19.teothetasWindow.gz.pestPG | awk '$14!="0" {print}' > teosinte19.TajD.txt"
echo $cmd
#eval $cmd

echo "End Job: "
date
```

Do calculate Tajima'D window of varying sizes we can use a batch script

Unfortunately not all windows are present in the resulting output (I think this is because not all windows have data) and so we need an additional few steps to make sure we keep the windows in order. To do this we can take advantge of the `GenomicRanges` package in R.